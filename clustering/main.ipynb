{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载金融数据集，处理离散数据，并标准化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(\"bank-data.csv\", index_col=0)\n",
    "dataset = pd.get_dummies(raw_dataset, dtype=int)\n",
    "dataset = (dataset - dataset.mean()) / dataset.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k_means` 函数使用 K-Means 算法进行聚类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(dataset: pd.DataFrame, num_clusters: int = 3):\n",
    "    # 随机挑选若干个点，作为聚类中心。\n",
    "    centers = dataset.sample(num_clusters)\n",
    "    centers.index = range(num_clusters)\n",
    "\n",
    "    # 存储聚类结果。\n",
    "    cluster_assignments = pd.Series(index=dataset.index)\n",
    "\n",
    "    # 不断更新聚类中心，直至收敛。\n",
    "    while True:\n",
    "        # 将每个点分配到最近的聚类中心。\n",
    "        new_cluster_assignments = dataset.apply(\n",
    "            lambda point: (centers - point).pow(2).sum(axis=1).pow(0.5).idxmin(),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # 如果与上一次的聚类结果相同，说明聚类已经收敛。\n",
    "        if new_cluster_assignments.equals(cluster_assignments):\n",
    "            break\n",
    "\n",
    "        # 否则，更新聚类结果。\n",
    "        cluster_assignments = new_cluster_assignments\n",
    "\n",
    "        # 根据新的聚类结果，计算新的聚类中心。\n",
    "        centers = dataset.groupby(cluster_assignments).mean()\n",
    "\n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dbscan` 函数使用 DBSCAN 算法进行聚类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(dataset: pd.DataFrame, eps: float = 10, min_samples: int = 3):\n",
    "    # 将所有点标记为未访问。\n",
    "    visited_points = pd.Series(False, index=dataset.index)\n",
    "\n",
    "    # 存储聚类结果。\n",
    "    cluster_assignments = pd.Series(index=dataset.index)\n",
    "\n",
    "    # 记录当前聚类的编号。\n",
    "    cluster_id = 0\n",
    "\n",
    "    # 计算每个点的邻域。\n",
    "    neighborhoods = dataset.apply(\n",
    "        lambda point: (dataset - point).pow(2).sum(axis=1).pow(0.5) <= eps,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # 从第一个点开始，依次访问每个点。\n",
    "    for point_id in dataset.index:\n",
    "        # 如果该点已经被访问过，则跳过。\n",
    "        if visited_points[point_id]:\n",
    "            continue\n",
    "\n",
    "        # 将该点标记为已访问。\n",
    "        visited_points[point_id] = True\n",
    "\n",
    "        # 计算该点的邻域。\n",
    "        neighborhood = neighborhoods[point_id]\n",
    "\n",
    "        # 如果该点的邻域中的点的数量小于 min_samples，将该点标记为噪声。\n",
    "        if neighborhood.sum() < min_samples:\n",
    "            cluster_assignments[point_id] = -1\n",
    "            continue\n",
    "\n",
    "        # 否则，将该点加入一个新的聚类。\n",
    "        cluster_id += 1\n",
    "        cluster_assignments[point_id] = cluster_id\n",
    "\n",
    "        # 依次访问该点的邻域中的点。\n",
    "        for neighbor_id in neighborhood[neighborhood].index:\n",
    "            # 如果该点已经被访问过，则跳过。\n",
    "            if visited_points[neighbor_id]:\n",
    "                continue\n",
    "\n",
    "            # 将该点标记为已访问。\n",
    "            visited_points[neighbor_id] = True\n",
    "\n",
    "            # 计算该点的邻域。\n",
    "            neighbor_neighborhood = neighborhoods[neighbor_id]\n",
    "\n",
    "            # 如果该点的邻域中的点的数量大于等于 min_samples，将该点加入当前聚类。\n",
    "            if neighbor_neighborhood.sum() >= min_samples:\n",
    "                cluster_assignments[neighbor_id] = cluster_id\n",
    "\n",
    "            # 否则，将该点标记为噪声。\n",
    "            else:\n",
    "                cluster_assignments[neighbor_id] = -1\n",
    "\n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    354\n",
       "2.0    197\n",
       "3.0     34\n",
       "4.0      8\n",
       "5.0      5\n",
       "6.0      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = dbscan(dataset, 7, 3)\n",
    "result.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comprehensive-curriculum-design-of-data-an-ZStDsHtf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
